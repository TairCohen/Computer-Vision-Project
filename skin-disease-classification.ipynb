{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2529450,"sourceType":"datasetVersion","datasetId":1532614}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nfrom PIL import Image, ImageFilter\nimport matplotlib.pyplot as plt\nimport random\nfrom sklearn.model_selection import train_test_split\nimport shutil\n\n# pytorch packages\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms\nfrom torchvision.models import resnet50, ResNet50_Weights, resnet101, ResNet101_Weights, densenet121, efficientnet_b0\nfrom torchinfo import summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:36:07.829033Z","iopub.execute_input":"2025-02-17T17:36:07.829256Z","iopub.status.idle":"2025-02-17T17:36:15.481301Z","shell.execute_reply.started":"2025-02-17T17:36:07.829232Z","shell.execute_reply":"2025-02-17T17:36:15.480643Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TODO optiona for imporvement - add more images from another database/ remove watermark","metadata":{}},{"cell_type":"markdown","source":"# Dermatological Conditions Classification\n### Run a classification CNN model on different types of dermatological conditions ","metadata":{}},{"cell_type":"code","source":"os.makedirs('data')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:36:22.143749Z","iopub.execute_input":"2025-02-17T17:36:22.144043Z","iopub.status.idle":"2025-02-17T17:36:22.147937Z","shell.execute_reply.started":"2025-02-17T17:36:22.144021Z","shell.execute_reply":"2025-02-17T17:36:22.147165Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Copy Selected Data to a New Data Folder:","metadata":{}},{"cell_type":"code","source":"data_path = \"/kaggle/input/skin-diseases-image-dataset/IMG_CLASSES/\"\ndest_path = '/kaggle/working/data/'\ndata_all = os.listdir(data_path)\nprint(data_all)\n\n\nskin_targets = [\"3. Atopic Dermatitis - 1.25k\", #'seborrheic-dermatitis-79.jpg', 'Psoriasis-Guttate-71.jpg'\n                \"7. Psoriasis pictures Lichen Planus and related diseases - 2k\", #'05AtopicWristq.jpg', '05keratosisPilaris080706.jpg'\n                \"1. Eczema 1677\", \n                \"9. Tinea Ringworm Candidiasis and other Fungal Infections - 1.7k\"\n               ] \n#0. Warts Molluscum and other Viral Infections - 2103\n#9. Tinea Ringworm Candidiasis and other Fungal Infections - 1.7k\n\nfor target in skin_targets:\n    target_path = data_path + target\n    target_dest_path = dest_path + target\n    print(f\"\\nTarget Name: {target}\")\n    print(f\"Train Len: {len(os.listdir(target_path))}\")\n    shutil.copytree(target_path, target_dest_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:36:24.780769Z","iopub.execute_input":"2025-02-17T17:36:24.781054Z","iopub.status.idle":"2025-02-17T17:37:35.869663Z","shell.execute_reply.started":"2025-02-17T17:36:24.781032Z","shell.execute_reply":"2025-02-17T17:37:35.869008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install split_folders\nimport splitfolders","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:37:40.233653Z","iopub.execute_input":"2025-02-17T17:37:40.233967Z","iopub.status.idle":"2025-02-17T17:37:43.435018Z","shell.execute_reply.started":"2025-02-17T17:37:40.233942Z","shell.execute_reply":"2025-02-17T17:37:43.433963Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree('/kaggle/working/data')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:33:06.204715Z","iopub.execute_input":"2025-02-17T17:33:06.205155Z","iopub.status.idle":"2025-02-17T17:33:06.210922Z","shell.execute_reply.started":"2025-02-17T17:33:06.205127Z","shell.execute_reply":"2025-02-17T17:33:06.209465Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Change Targets' Names:","metadata":{}},{"cell_type":"code","source":"path = \"/kaggle/working/data/\"\n\ndir_list = os.listdir(path) \nprint(len(dir_list))\n\nos.rename(path + \"1. Eczema 1677\", path + \"Eczema\")\nos.rename(path + \"7. Psoriasis pictures Lichen Planus and related diseases - 2k\", path + \"Psoriasis + Lichen Planus\")\nos.rename(path + \"3. Atopic Dermatitis - 1.25k\", path + \"Atopic Dermatitis\")\nos.rename(path + \"9. Tinea Ringworm Candidiasis and other Fungal Infections - 1.7k\", path + \"Fungal Infections\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:38:17.725879Z","iopub.execute_input":"2025-02-17T17:38:17.726240Z","iopub.status.idle":"2025-02-17T17:38:17.732559Z","shell.execute_reply.started":"2025-02-17T17:38:17.726209Z","shell.execute_reply":"2025-02-17T17:38:17.731654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = \"/kaggle/working/data\"\n\nskin_targets_renamed = os.listdir(path)\nskin_targets_renamed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:38:20.789062Z","iopub.execute_input":"2025-02-17T17:38:20.789435Z","iopub.status.idle":"2025-02-17T17:38:20.796283Z","shell.execute_reply.started":"2025-02-17T17:38:20.789395Z","shell.execute_reply":"2025-02-17T17:38:20.795603Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Split Data to Train, Test and Validation Folders","metadata":{}},{"cell_type":"code","source":"os.makedirs('split_data')\nos.makedirs('split_data/train')\nos.makedirs('split_data/val')\nos.makedirs('split_data/test')\n\nloc = \"/kaggle/working/data/\"\n\nsplitfolders.ratio(loc, output =\"split_data\", ratio = (0.80,.1,.1))\n# splitfolders.ratio(loc, output =\"split_data\", ratio = (0.70,.15,.15))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:38:26.118132Z","iopub.execute_input":"2025-02-17T17:38:26.118552Z","iopub.status.idle":"2025-02-17T17:38:27.406306Z","shell.execute_reply.started":"2025-02-17T17:38:26.118518Z","shell.execute_reply":"2025-02-17T17:38:27.405595Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = \"/kaggle/working/split_data/train/Atopic Dermatitis\"\ndir_list = os.listdir(path) \nprint(len(dir_list))\n# dir_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:38:30.120407Z","iopub.execute_input":"2025-02-17T17:38:30.120702Z","iopub.status.idle":"2025-02-17T17:38:30.125947Z","shell.execute_reply.started":"2025-02-17T17:38:30.120679Z","shell.execute_reply":"2025-02-17T17:38:30.125252Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# PNG is o.k??? next do jpg","metadata":{}},{"cell_type":"code","source":"path = \"/kaggle/working/split_data/train/\"\nfor target in skin_targets_renamed:\n    dir_path = path + target\n    dir_list = os.listdir(dir_path) \n    for image_name in dir_list:\n        image_path = dir_path + \"/\" + image_name\n        image = Image.open(image_path)\n        # transform = transforms.RandomRotation(30)\n        # flipped_30_image = transform(image)\n        # flipped_30_image.save(f\"{image_path.replace('.jpg', '')}_30_flipped.jpg\")\n        transform = transforms.RandomHorizontalFlip(p=1)\n        horizontal_flipped_image = transform(image)\n        horizontal_flipped_image.save(f\"{image_path.replace('.jpg', '')}_horizontal_flipped.jpg\")\n        transform = transforms.ColorJitter(brightness=0.2, contrast=0.2)\n        color_jitter_image = transform(image)\n        color_jitter_image.save(f\"{image_path.replace('.jpg', '')}_color_jitter.jpg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T09:22:27.753960Z","iopub.execute_input":"2025-02-11T09:22:27.754294Z","iopub.status.idle":"2025-02-11T09:23:20.177568Z","shell.execute_reply.started":"2025-02-11T09:22:27.754260Z","shell.execute_reply":"2025-02-11T09:23:20.176690Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from glob import glob\nimage_name = \"t-neurotic-excoriations-12\" #\"t-Dyshidrosis-17\"\nglob(f\"/kaggle/working/split_data/train/Eczema/{image_name}*\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T09:25:17.090311Z","iopub.execute_input":"2025-02-11T09:25:17.090645Z","iopub.status.idle":"2025-02-11T09:25:17.100492Z","shell.execute_reply.started":"2025-02-11T09:25:17.090620Z","shell.execute_reply":"2025-02-11T09:25:17.099790Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, axes = plt.subplots(2, 2)\nimage = Image.open(\"/kaggle/working/split_data/train/Eczema/\" + image_name + \".jpg\")\naxes[0][0].imshow(image)\naxes[0][0].set_title(f\"{image_name} \\nOriginal Image\", fontsize = 10)\naxes[0][0].axis('off')\n# flipped_30_image = Image.open(\"/kaggle/working/split_data/train/Eczema/\" + image_name + \"_30_flipped.jpg\")\n# axes[0][1].imshow(flipped_30_image)\n# axes[0][1].set_title(f\"{image_name} \\nRandomly Flipped 30 Image\", fontsize = 10)\naxes[0][1].axis('off')\nhorizontal_flipped_image = Image.open(\"/kaggle/working/split_data/train/Eczema/\" + image_name + \"_horizontal_flipped.jpg\")\naxes[1][0].imshow(horizontal_flipped_image)\naxes[1][0].set_title(f\"{image_name} \\nHorizontal Flipped Image\", fontsize = 10)\naxes[1][0].axis('off')\ncolor_jitter_image = Image.open(\"/kaggle/working/split_data/train/Eczema/\" + image_name + \"_color_jitter.jpg\")\naxes[1][1].imshow(color_jitter_image)\naxes[1][1].set_title(f\"{image_name} \\nColor Jitter Image\", fontsize = 10)\naxes[1][1].axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T09:25:31.233398Z","iopub.execute_input":"2025-02-11T09:25:31.233702Z","iopub.status.idle":"2025-02-11T09:25:31.625743Z","shell.execute_reply.started":"2025-02-11T09:25:31.233669Z","shell.execute_reply":"2025-02-11T09:25:31.624779Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Create pytorch dataset","metadata":{}},{"cell_type":"code","source":"train_path = \"/kaggle/working/split_data/train/\"\ntest_path = \"/kaggle/working/split_data/test/\"\n\n# implement pytorch dataset:\nclass SkinDataset(Dataset):\n\n    def __init__(self, mode = 'train', transform = transforms.ToTensor()):\n        self.mode = mode \n        self.target_dict = {}\n        self.skin_targets = skin_targets_renamed\n        img_paths, img_targets = self.get_data()\n        self.img_paths = img_paths\n        self.img_targets = img_targets\n        self.transform = transform\n        \n    def __len__(self): # == len(dataset)\n        return len(self.img_paths)\n        \n    def __getitem__(self, index): # == dataset[index] \n        img = Image.open(self.img_paths[index])\n        # img = img.filter(ImageFilter.GaussianBlur(radius=2)) #reduce noises\n        img = self.transform(img)\n        return {\"img\": img, \"target\": self.img_targets[index]}\n\n    def get_data(self):\n        dir_path = train_path if self.mode == 'train' else test_path\n        image_paths = []\n        image_target = []\n        for i in range(len(skin_targets)):\n            target_path = dir_path + self.skin_targets[i]\n            self.target_dict[i] = self.skin_targets[i]\n            print(f\"target_path: {target_path}\")\n            for path in os.listdir(target_path):\n                img_path = target_path + \"/\" + path\n                image_paths.append(img_path)\n                image_target.append(i) # target index\n        return image_paths, image_target\n\n\n# train_transform = transforms.Compose([\n#     transforms.RandomHorizontalFlip(p=0.5),  # Flip images horizontally\n#     transforms.RandomRotation(degrees=30),  # Rotate slightly\n#     transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Change brightness & contrast\n#     transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Crop randomly\n#     transforms.RandomAffine(degrees=0, shear=10),  # Apply small shearing\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n# ])\n\ntrain_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(p=0.5),   # Flip images randomly\n    transforms.RandomRotation(degrees=20),    # Rotate more (10 → 20 degrees)\n    transforms.RandomResizedCrop(224, scale=(0.6, 1.0)),  # More aggressive cropping\n    transforms.RandomAffine(degrees=0, shear=20),  # Increase shear for perspective shifts\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),  # Stronger distortions\n    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),  # Apply perspective transformation\n    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0)),  # Blur to prevent memorization\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Standard normalization\n    # transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3))  # Cutout to hide parts of the image\n    transforms.RandomErasing(p=0.5)  # Cutout to hide parts of the image\n])\n\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),  # No augmentation for validation\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n\ntrain = SkinDataset(mode = 'train', transform = train_transform)\nprint(f\"train len: {len(train)}\") \n\ntest = SkinDataset(mode = 'test', transform = test_transform)\nprint(f\"test len: {len(test)}\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:38:35.484313Z","iopub.execute_input":"2025-02-17T17:38:35.484610Z","iopub.status.idle":"2025-02-17T17:38:35.503849Z","shell.execute_reply.started":"2025-02-17T17:38:35.484575Z","shell.execute_reply":"2025-02-17T17:38:35.503096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"example_list = [train[i] for i in random.sample(range(len(train)), k=12)]\n\nfig, axes = plt.subplots(3, 4, figsize=(10, 8))\nfor ax, img_item in zip(axes.ravel(), example_list):\n    img = transforms.functional.to_pil_image(img_item['img'])\n    ax.imshow(img)\n    ax.axis('off')\n    ax.set_title(train.target_dict[img_item['target']], fontsize=10, color=\"blue\")\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:38:39.861795Z","iopub.execute_input":"2025-02-17T17:38:39.862086Z","iopub.status.idle":"2025-02-17T17:38:41.219253Z","shell.execute_reply.started":"2025-02-17T17:38:39.862063Z","shell.execute_reply":"2025-02-17T17:38:41.218317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set the device\nc_device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\npin_memory = c_device.type == 'cuda'\nprint(f\"device: {c_device}\")\n\n# Create dataloaders for training and test sets\ntrain_loader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True, pin_memory=pin_memory)\ntest_loader = torch.utils.data.DataLoader(test, batch_size=64, pin_memory=pin_memory)\n\nbatch = next(iter(train_loader))\nprint(batch['img'].shape)\nprint(batch['target'].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:38:49.435643Z","iopub.execute_input":"2025-02-17T17:38:49.435923Z","iopub.status.idle":"2025-02-17T17:38:50.883337Z","shell.execute_reply.started":"2025-02-17T17:38:49.435903Z","shell.execute_reply":"2025-02-17T17:38:50.882535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_loop(dataloader, model, criterion, optimizer, device):\n    size = len(dataloader.dataset)\n    model.train()\n    running_loss, running_corrects = 0, 0\n    # iterate through all batches\n    for batch in dataloader:\n        X = batch['img'].to(device=device)\n        y = batch['target'].to(device=device)\n        pred = model(X)\n        loss = criterion(pred, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        running_corrects += (pred.argmax(1) == y).type(torch.float).sum().item()\n    epoch_loss = running_loss / size\n    epoch_accuracy = 100 * running_corrects / size\n    return epoch_loss, epoch_accuracy\n\n\ndef inference_loop(dataloader, model, criterion, device):\n    size = len(dataloader.dataset)\n    model.eval()\n    running_loss, running_corrects = 0, 0\n    # disregard gradients when not training\n    with torch.no_grad():\n        # iterate through all batches\n        for batch in dataloader:\n            X = batch['img'].to(device=device)\n            y = batch['target'].to(device=device)\n            pred = model(X)\n            running_loss += criterion(pred, y).item()\n            running_corrects += (pred.argmax(1) == y).type(torch.float).sum().item()\n    epoch_loss = running_loss / size\n    epoch_accuracy = 100 * running_corrects / size\n    return epoch_loss, epoch_accuracy","metadata":{"execution":{"iopub.status.busy":"2025-02-17T17:38:55.372384Z","iopub.execute_input":"2025-02-17T17:38:55.372686Z","iopub.status.idle":"2025-02-17T17:38:55.380669Z","shell.execute_reply.started":"2025-02-17T17:38:55.372662Z","shell.execute_reply":"2025-02-17T17:38:55.379635Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Add dropout layer to the network\n#### Allowing \"shot down\" layers randomly to reduce overfitting","metadata":{}},{"cell_type":"code","source":"# Load the pre-trained ResNet-50 model\n# model = resnet50(weights=None)\n# model = resnet101(weights=None)\n# model = resnet50(weights=\"IMAGENET1K_V1\")\n# model = densenet121(weights=None)\n\n# summary(model, input_size=(64, 3, 224, 224))  # Batch size 1, 3 channels, 224x224 image\n\n\n# class CustomDenseNet(nn.Module):\n#     def __init__(self, num_classes):\n#         super(CustomDenseNet, self).__init__()\n#         self.base_model = densenet121(weights=None)\n        \n#         # Correct classifier replacement\n#         self.base_model.classifier = nn.Sequential(\n#             nn.Dropout(p=0.5),  # Dropout for regularization, change to 0.6??\n#             nn.Linear(1024, num_classes) \n#         )\n\n#     def forward(self, x):\n#         x = self.base_model(x)  # DenseNet already includes feature extraction\n#         return x\n\n# model = CustomDenseNet(num_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-11T11:56:03.084304Z","iopub.execute_input":"2025-02-11T11:56:03.084605Z","iopub.status.idle":"2025-02-11T11:56:03.089453Z","shell.execute_reply.started":"2025-02-11T11:56:03.084583Z","shell.execute_reply":"2025-02-11T11:56:03.088414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = densenet121(weights=None)\nnum_classes = 4\nmodel = efficientnet_b0(weights=\"IMAGENET1K_V1\")  # Load pre-trained weights\nmodel.classifier = nn.Sequential(\n    nn.Dropout(0.6),\n    nn.Linear(model.classifier[1].in_features, num_classes)  # Adjust output layer\n)\n\n# Transfer it to device\nmodel = model.to(device=c_device)\n\n\n# Define the loss function\ncriterion = nn.CrossEntropyLoss()\n\n# define optimizer & schedulers\n# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)  # Use all parameters\n# optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n# optimizer = optim.Adam(model.parameters(), lr=1e-4)\noptimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)  # Reduce LR every n epochs by a factor of 0.5\n\nepochs = 40\nfor epoch in range(1, epochs + 1):\n    train_loss, train_acc = train_loop(train_loader, model, criterion, optimizer, c_device)\n    test_loss, test_acc = inference_loop(test_loader, model, criterion, c_device)\n    if True or epoch % 5 == 0:\n        print('Train', f'Epoch: {epoch:03d} / {epochs:03d}',  f'Loss: {train_loss:7.4g}', f'Accuracy: {train_acc:.3f}',  sep='   ')\n        print(' Test', f'Epoch: {epoch:03d} / {epochs:03d}',  f'Loss: {test_loss:7.4g}', f'Accuracy: {test_acc:.3f}', sep='   ')\n    scheduler.step()\n\n\n# 20 epochs, step_size=10, 20: train: 0.75, test: 0.55\n# densenet121 model: 90 epochs, step_size=20, adam, lr=0.001, normalization, train: 97.920, test: 62.948\n# CustomDenseNet model without augmentation: 30-40 epochs, step_size=20, adam, lr=0.001, normalization, train: 98.9, test: 73-75\n# when doing augmentation lr should be small\n# CustomDenseNet model with saved augmentation: 34 epochs, step_size=20, adam, lr=0.001, normalization, train: 91, test: 64 - similar results with more weak augmentation train: 99, test: 66\n# efficientnet_b0 trained model - much better!! 14 epochs, train: 97, test: 76\n# efficientnet_b0 trained model with fly augmentation best!! 11 epochs, train: 94, test: 78\n# with 30-degree rot Train   Epoch: 026 / 040   Accuracy: 96.190 Test Accuracy: 78-80.677\n# with erase : Train   Epoch: 025 / 040  Accuracy: 86.591 Test Accuracy: 75.498 - less overfitting but not very good performence\n\n# with fugal : Epoch: 025 / 040  Accuracy: 84 Test Accuracy: 71-73","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T17:39:28.802162Z","iopub.execute_input":"2025-02-17T17:39:28.802499Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### TODO add confusion_matrix (actual vs predicted) and loss and accurcy graph \nhttps://www.nature.com/articles/s41598-024-80013-0","metadata":{}}]}